{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f2b64fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as sm \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3568134",
   "metadata": {},
   "source": [
    "def iqr(data)  \n",
    "    # First quartile (Q1)\n",
    "    Q1 = np.percentile(data, 25, interpolation = 'midpoint')\n",
    "\n",
    "    # Third quartile (Q3)\n",
    "    Q3 = np.percentile(data, 75, interpolation = 'midpoint')\n",
    "\n",
    "    # Interquaritle range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    return Q1,Q3,IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b9cf77",
   "metadata": {},
   "source": [
    "# Read the parquet file for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f3285",
   "metadata": {},
   "source": [
    "##### Compressing the data set by changing the customer id to int64 and to hex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b36141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data...\n",
      "shape of data: (5531451, 190)\n"
     ]
    }
   ],
   "source": [
    "def read_parquet(path='', cols=None):\n",
    "    \"\"\"\n",
    "        Returns pandas dataframe\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        path to training data in parquet format\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Pandas DataFrame\n",
    "\n",
    "        \"\"\"\n",
    "    # LOAD DATAFRAME\n",
    "    if cols is not None:\n",
    "        dataFrame = pd.read_parquet(path, columns=cols)\n",
    "    else:\n",
    "        dataFrame = pd.read_parquet(path)\n",
    "\n",
    "    \n",
    "    dataFrame['customer_ID'] = dataFrame['customer_ID'].str[-16:].apply(int, base=16).astype('int64')\n",
    "    dataFrame.S_2 = pd.to_datetime(dataFrame.S_2)\n",
    "\n",
    "    \n",
    "    dataFrame = dataFrame.fillna(-127)\n",
    "    print('shape of data:', dataFrame.shape)\n",
    "\n",
    "    return dataFrame\n",
    "\n",
    "\n",
    "print('Reading train data...')\n",
    "TRAIN_PATH = 'train.parquet'\n",
    "train = read_parquet(path=TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4002b",
   "metadata": {},
   "source": [
    "# Feature engineering is done seperately for numerical columns and categorical columns and then groupby using the date as there are a lot a record for each customer for seperate statements. Agreegation is done using min,max,last,std, count etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea0fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after engineering (458913, 918)\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    :param df: pandas dataframe of train dataset\n",
    "    :return: feature engineered data\n",
    "    \n",
    "    \"\"\"\n",
    "    all_col_of_df = [c for c in list(df.columns) if c not in ['customer_ID', 'S_2']]\n",
    "    cat_features = [\"B_30\", \"B_38\", \"D_114\", \"D_116\", \"D_117\", \"D_120\", \"D_126\", \"D_63\", \"D_64\", \"D_66\", \"D_68\"]\n",
    "    num_features = [col for col in all_col_of_df if col not in cat_features]\n",
    "\n",
    "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "\n",
    "    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "\n",
    "    df = pd.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print('shape after engineering', df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_engineering(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b81b9a",
   "metadata": {},
   "source": [
    "# The target variable is added to the groupby dataset by merging common records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f863c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 918 features!\n"
     ]
    }
   ],
   "source": [
    "# ADD TARGETS\n",
    "output_var = pd.read_csv('C:/Users/shant/Downloads/train_labels.csv')\n",
    "output_var['customer_ID'] = output_var['customer_ID'].str[-16:].apply(int, base=16).astype('int64')\n",
    "output_var = output_var.set_index('customer_ID')\n",
    "train = train.merge(output_var, left_index=True, right_index=True, how='left')\n",
    "train.target = train.target.astype('int8')\n",
    "del output_var\n",
    "\n",
    "\n",
    "train = train.sort_index().reset_index()\n",
    "\n",
    "# FEATURES\n",
    "FEATURES = train.columns[1:-1]\n",
    "print(f'There are {len(FEATURES)} features!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae8fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['P_2_std', 'D_39_std', 'B_1_std', 'B_2_std', 'R_1_std', 'S_3_std',\n",
       "       'D_41_std', 'B_3_std', 'D_42_std', 'D_43_std',\n",
       "       ...\n",
       "       'D_136_std', 'D_137_std', 'D_138_std', 'D_139_std', 'D_140_std',\n",
       "       'D_141_std', 'D_142_std', 'D_143_std', 'D_144_std', 'D_145_std'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()[train.isnull().sum() != 0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e6ec21",
   "metadata": {},
   "source": [
    "# Since missing value count is less then 1% so missing value data are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15498c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records removed:  5120\n",
      "% of customers removed from data:  1.1156798783211632\n"
     ]
    }
   ],
   "source": [
    "shape_before_remove = train.shape[0]\n",
    "train = train.dropna()\n",
    "print('Number of records removed: ',abs(shape_before_remove - train.shape[0]))\n",
    "print('% of customers removed from data: ', abs(shape_before_remove - train.shape[0]) * 100 /shape_before_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37366c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>D_63_nunique</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.537930e+05</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.857061e+15</td>\n",
       "      <td>-0.836002</td>\n",
       "      <td>1.831865</td>\n",
       "      <td>-4.517465</td>\n",
       "      <td>0.143169</td>\n",
       "      <td>-0.089036</td>\n",
       "      <td>4.986713</td>\n",
       "      <td>5.725742</td>\n",
       "      <td>0.158920</td>\n",
       "      <td>16.885796</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072941</td>\n",
       "      <td>12.178088</td>\n",
       "      <td>1.169522</td>\n",
       "      <td>1.436225</td>\n",
       "      <td>12.178088</td>\n",
       "      <td>-0.769785</td>\n",
       "      <td>1.038445</td>\n",
       "      <td>12.178088</td>\n",
       "      <td>4.928040</td>\n",
       "      <td>1.602277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.328744e+18</td>\n",
       "      <td>10.446057</td>\n",
       "      <td>9.666892</td>\n",
       "      <td>25.002823</td>\n",
       "      <td>8.539724</td>\n",
       "      <td>9.582557</td>\n",
       "      <td>5.424514</td>\n",
       "      <td>5.302279</td>\n",
       "      <td>1.342613</td>\n",
       "      <td>16.069912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287971</td>\n",
       "      <td>2.344432</td>\n",
       "      <td>1.376439</td>\n",
       "      <td>0.592898</td>\n",
       "      <td>2.344432</td>\n",
       "      <td>0.638304</td>\n",
       "      <td>0.194184</td>\n",
       "      <td>2.344432</td>\n",
       "      <td>1.492104</td>\n",
       "      <td>0.734291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.223358e+18</td>\n",
       "      <td>-127.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-127.000000</td>\n",
       "      <td>-127.000000</td>\n",
       "      <td>-127.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.620310e+18</td>\n",
       "      <td>0.448502</td>\n",
       "      <td>0.022928</td>\n",
       "      <td>0.356623</td>\n",
       "      <td>0.549564</td>\n",
       "      <td>0.445101</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.976669e+15</td>\n",
       "      <td>0.671380</td>\n",
       "      <td>0.038433</td>\n",
       "      <td>0.595314</td>\n",
       "      <td>0.747344</td>\n",
       "      <td>0.681235</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>5.547002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.612774e+18</td>\n",
       "      <td>0.854776</td>\n",
       "      <td>0.067619</td>\n",
       "      <td>0.796277</td>\n",
       "      <td>0.907235</td>\n",
       "      <td>0.861990</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>8.166536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.223350e+18</td>\n",
       "      <td>1.009089</td>\n",
       "      <td>90.515988</td>\n",
       "      <td>1.008194</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.009998</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>103.944697</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        customer_ID       P_2_mean        P_2_std        P_2_min  \\\n",
       "count  4.537930e+05  453793.000000  453793.000000  453793.000000   \n",
       "mean  -3.857061e+15      -0.836002       1.831865      -4.517465   \n",
       "std    5.328744e+18      10.446057       9.666892      25.002823   \n",
       "min   -9.223358e+18    -127.000000       0.000000    -127.000000   \n",
       "25%   -4.620310e+18       0.448502       0.022928       0.356623   \n",
       "50%    2.976669e+15       0.671380       0.038433       0.595314   \n",
       "75%    4.612774e+18       0.854776       0.067619       0.796277   \n",
       "max    9.223350e+18       1.009089      90.515988       1.008194   \n",
       "\n",
       "             P_2_max       P_2_last      D_39_mean       D_39_std  \\\n",
       "count  453793.000000  453793.000000  453793.000000  453793.000000   \n",
       "mean        0.143169      -0.089036       4.986713       5.725742   \n",
       "std         8.539724       9.582557       5.424514       5.302279   \n",
       "min      -127.000000    -127.000000       0.000000       0.000000   \n",
       "25%         0.549564       0.445101       0.538462       0.960769   \n",
       "50%         0.747344       0.681235       3.615385       5.547002   \n",
       "75%         0.907235       0.861990       7.692308       8.166536   \n",
       "max         1.010000       1.009998     156.000000     103.944697   \n",
       "\n",
       "            D_39_min       D_39_max  ...   D_63_nunique     D_64_count  \\\n",
       "count  453793.000000  453793.000000  ...  453793.000000  453793.000000   \n",
       "mean        0.158920      16.885796  ...       1.072941      12.178088   \n",
       "std         1.342613      16.069912  ...       0.287971       2.344432   \n",
       "min         0.000000       0.000000  ...       1.000000       2.000000   \n",
       "25%         0.000000       3.000000  ...       1.000000      13.000000   \n",
       "50%         0.000000      16.000000  ...       1.000000      13.000000   \n",
       "75%         0.000000      23.000000  ...       1.000000      13.000000   \n",
       "max       151.000000     183.000000  ...       6.000000      13.000000   \n",
       "\n",
       "           D_64_last   D_64_nunique     D_66_count      D_66_last  \\\n",
       "count  453793.000000  453793.000000  453793.000000  453793.000000   \n",
       "mean        1.169522       1.436225      12.178088      -0.769785   \n",
       "std         1.376439       0.592898       2.344432       0.638304   \n",
       "min        -1.000000       1.000000       2.000000      -1.000000   \n",
       "25%         0.000000       1.000000      13.000000      -1.000000   \n",
       "50%         0.000000       1.000000      13.000000      -1.000000   \n",
       "75%         3.000000       2.000000      13.000000      -1.000000   \n",
       "max         3.000000       5.000000      13.000000       1.000000   \n",
       "\n",
       "        D_66_nunique     D_68_count      D_68_last   D_68_nunique  \n",
       "count  453793.000000  453793.000000  453793.000000  453793.000000  \n",
       "mean        1.038445      12.178088       4.928040       1.602277  \n",
       "std         0.194184       2.344432       1.492104       0.734291  \n",
       "min         1.000000       2.000000      -1.000000       1.000000  \n",
       "25%         1.000000      13.000000       4.000000       1.000000  \n",
       "50%         1.000000      13.000000       6.000000       1.000000  \n",
       "75%         1.000000      13.000000       6.000000       2.000000  \n",
       "max         3.000000      13.000000       6.000000       6.000000  \n",
       "\n",
       "[8 rows x 919 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(\"target\",axis=1)\n",
    "y= train[\"target\"]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f550d",
   "metadata": {},
   "source": [
    "def outlierdetection(df):\n",
    "    \n",
    "    q1=df.quantile(0.25)\n",
    "\n",
    "    q3=df.quantile(0.75)\n",
    "\n",
    "    IQR=q3-q1\n",
    "\n",
    "    outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "\n",
    "    return outliers \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb8334",
   "metadata": {},
   "source": [
    "train.to_csv('C:/Users/aagarw16/OneDrive - stevens.edu/Desktop/ML Project/Project/Data_transformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d8061",
   "metadata": {},
   "source": [
    "# We apply Robust Scaling to the data set to get the outliers into the range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c16347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform= RobustScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c524f597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.999269  , -0.62891364,  0.41871238, ...,  0.        ,\n",
       "        -1.5       ,  1.        ],\n",
       "       [-0.99925109,  0.74503548, -0.56698068, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.99925073,  0.32260794, -0.00912282, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.99861823, -0.75459455,  0.8142958 , ...,  0.        ,\n",
       "        -1.5       ,  1.        ],\n",
       "       [ 0.99862279,  0.43691329,  0.47225463, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.99862332, -1.07944177,  0.58651556, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "726ac216",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform1 = pd.DataFrame(X_transform,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c44b96ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>D_63_nunique</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000740</td>\n",
       "      <td>-3.710255</td>\n",
       "      <td>40.129720</td>\n",
       "      <td>-11.629391</td>\n",
       "      <td>-1.689170</td>\n",
       "      <td>-1.847658</td>\n",
       "      <td>0.191691</td>\n",
       "      <td>0.024805</td>\n",
       "      <td>0.158920</td>\n",
       "      <td>0.044290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072941</td>\n",
       "      <td>-0.821912</td>\n",
       "      <td>0.389841</td>\n",
       "      <td>0.436225</td>\n",
       "      <td>-0.821912</td>\n",
       "      <td>0.230215</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>-0.821912</td>\n",
       "      <td>-0.535980</td>\n",
       "      <td>0.602277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.577136</td>\n",
       "      <td>25.702302</td>\n",
       "      <td>216.305759</td>\n",
       "      <td>56.806572</td>\n",
       "      <td>23.907053</td>\n",
       "      <td>23.015027</td>\n",
       "      <td>0.758265</td>\n",
       "      <td>0.735838</td>\n",
       "      <td>1.342613</td>\n",
       "      <td>0.803496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287971</td>\n",
       "      <td>2.344432</td>\n",
       "      <td>0.458813</td>\n",
       "      <td>0.592898</td>\n",
       "      <td>2.344432</td>\n",
       "      <td>0.638304</td>\n",
       "      <td>0.194184</td>\n",
       "      <td>2.344432</td>\n",
       "      <td>0.746052</td>\n",
       "      <td>0.734291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.999269</td>\n",
       "      <td>-314.249453</td>\n",
       "      <td>-0.859969</td>\n",
       "      <td>-290.217592</td>\n",
       "      <td>-357.164425</td>\n",
       "      <td>-306.270937</td>\n",
       "      <td>-0.505376</td>\n",
       "      <td>-0.769800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.500731</td>\n",
       "      <td>-0.548590</td>\n",
       "      <td>-0.346939</td>\n",
       "      <td>-0.542908</td>\n",
       "      <td>-0.552966</td>\n",
       "      <td>-0.566419</td>\n",
       "      <td>-0.430108</td>\n",
       "      <td>-0.636467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.650000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.499269</td>\n",
       "      <td>0.451410</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.457092</td>\n",
       "      <td>0.447034</td>\n",
       "      <td>0.433581</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.363533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998623</td>\n",
       "      <td>0.831236</td>\n",
       "      <td>2024.520064</td>\n",
       "      <td>0.939102</td>\n",
       "      <td>0.734351</td>\n",
       "      <td>0.788610</td>\n",
       "      <td>21.301075</td>\n",
       "      <td>13.655409</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer_ID       P_2_mean        P_2_std        P_2_min  \\\n",
       "count  453793.000000  453793.000000  453793.000000  453793.000000   \n",
       "mean       -0.000740      -3.710255      40.129720     -11.629391   \n",
       "std         0.577136      25.702302     216.305759      56.806572   \n",
       "min        -0.999269    -314.249453      -0.859969    -290.217592   \n",
       "25%        -0.500731      -0.548590      -0.346939      -0.542908   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.499269       0.451410       0.653061       0.457092   \n",
       "max         0.998623       0.831236    2024.520064       0.939102   \n",
       "\n",
       "             P_2_max       P_2_last      D_39_mean       D_39_std  \\\n",
       "count  453793.000000  453793.000000  453793.000000  453793.000000   \n",
       "mean       -1.689170      -1.847658       0.191691       0.024805   \n",
       "std        23.907053      23.015027       0.758265       0.735838   \n",
       "min      -357.164425    -306.270937      -0.505376      -0.769800   \n",
       "25%        -0.552966      -0.566419      -0.430108      -0.636467   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.447034       0.433581       0.569892       0.363533   \n",
       "max         0.734351       0.788610      21.301075      13.655409   \n",
       "\n",
       "            D_39_min       D_39_max  ...   D_63_nunique     D_64_count  \\\n",
       "count  453793.000000  453793.000000  ...  453793.000000  453793.000000   \n",
       "mean        0.158920       0.044290  ...       0.072941      -0.821912   \n",
       "std         1.342613       0.803496  ...       0.287971       2.344432   \n",
       "min         0.000000      -0.800000  ...       0.000000     -11.000000   \n",
       "25%         0.000000      -0.650000  ...       0.000000       0.000000   \n",
       "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "75%         0.000000       0.350000  ...       0.000000       0.000000   \n",
       "max       151.000000       8.350000  ...       5.000000       0.000000   \n",
       "\n",
       "           D_64_last   D_64_nunique     D_66_count      D_66_last  \\\n",
       "count  453793.000000  453793.000000  453793.000000  453793.000000   \n",
       "mean        0.389841       0.436225      -0.821912       0.230215   \n",
       "std         0.458813       0.592898       2.344432       0.638304   \n",
       "min        -0.333333       0.000000     -11.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       1.000000       0.000000       0.000000   \n",
       "max         1.000000       4.000000       0.000000       2.000000   \n",
       "\n",
       "        D_66_nunique     D_68_count      D_68_last   D_68_nunique  \n",
       "count  453793.000000  453793.000000  453793.000000  453793.000000  \n",
       "mean        0.038445      -0.821912      -0.535980       0.602277  \n",
       "std         0.194184       2.344432       0.746052       0.734291  \n",
       "min         0.000000     -11.000000      -3.500000       0.000000  \n",
       "25%         0.000000       0.000000      -1.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000       1.000000  \n",
       "max         2.000000       0.000000       0.000000       5.000000  \n",
       "\n",
       "[8 rows x 919 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b4322c",
   "metadata": {},
   "source": [
    "# We use IQR method to find the number of columns having outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5f6f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_1 = X_transform1.quantile(0.25)\n",
    "Q3_1 = X_transform1.quantile(0.75)\n",
    "IQR_1 = Q3_1 - Q1_1\n",
    "y_value1=((X_transform1 < (Q1_1 - 1.5 * IQR_1)) | (X_transform1 > (Q3_1 + 1.5 * IQR_1))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552a348",
   "metadata": {},
   "source": [
    "# All columns where having outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6342913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    919\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_value1/X_transform1.shape[0])>1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a353f2",
   "metadata": {},
   "source": [
    "# Finding the Percentage of outliers in each columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "244211ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = X.quantile(0.25)\n",
    "Q3 = X.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "y_value=((((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).sum())/X.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e189619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_ID     0.000000\n",
       "P_2_mean        0.040089\n",
       "P_2_std         0.083064\n",
       "P_2_min         0.040250\n",
       "P_2_max         0.005522\n",
       "                  ...   \n",
       "D_66_last       0.115108\n",
       "D_66_nunique    0.038075\n",
       "D_68_count      0.149317\n",
       "D_68_last       0.014641\n",
       "D_68_nunique    0.015798\n",
       "Length: 919, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec1a16",
   "metadata": {},
   "source": [
    "# Calculating the number of columns having outlier greater then 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f894d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    713\n",
       "True     206\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((y_value1/X_transform1.shape[0])*100)>15).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7932da",
   "metadata": {},
   "source": [
    "# 216 columns have outliers more then 15% and rest less then 15% so we could apply ANN and other linear algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "151b8113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_ID     False\n",
       "P_2_mean        False\n",
       "P_2_std         False\n",
       "P_2_min         False\n",
       "P_2_max         False\n",
       "                ...  \n",
       "D_66_last       False\n",
       "D_66_nunique    False\n",
       "D_68_count      False\n",
       "D_68_last       False\n",
       "D_68_nunique    False\n",
       "Length: 919, dtype: bool"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((y_value/X.shape[0])*100)>15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca567e0",
   "metadata": {},
   "source": [
    "# Train Test Spliting done on the X_Transformed after applying Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ff907",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transform1,y,test_size=0.3, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4feff26",
   "metadata": {},
   "source": [
    "# Training using SVM classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94504cd",
   "metadata": {},
   "source": [
    "# With the available resources due to the high computational requirement of SVM for multidimensional data SVM even after running for 72 hours it was still excuting which is not a feasible model as for hyper parameter tuning the model would require to much time and computation. Also outliers where not handled due to no concrete method for handling them currently for linear model. So SVM was replaced with another Tree based algorithm XGboost which is Outlier invarient and also works very well on high dimension data with added advantage of learning from prior and adjusting the training in each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a299908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
