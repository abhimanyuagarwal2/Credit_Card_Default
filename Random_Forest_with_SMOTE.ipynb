{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2b64fc",
   "metadata": {
    "id": "7f2b64fc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as sm \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b36141",
   "metadata": {
    "id": "15b36141",
    "outputId": "30bbcf55-cd6f-452e-a18e-fdf4e37b2cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data...\n",
      "shape of data: (5531451, 190)\n"
     ]
    }
   ],
   "source": [
    "def read_parquet(path='', cols=None):\n",
    "    \"\"\"\n",
    "        Returns pandas dataframe\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        path to training data in parquet format\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Pandas DataFrame\n",
    "\n",
    "        \"\"\"\n",
    "    # LOAD DATAFRAME\n",
    "    if cols is not None:\n",
    "        dataFrame = pd.read_parquet(path, columns=cols)\n",
    "    else:\n",
    "        dataFrame = pd.read_parquet(path)\n",
    "\n",
    "    \n",
    "    dataFrame['customer_ID'] = dataFrame['customer_ID'].str[-16:].apply(int, base=16).astype('int64')\n",
    "    dataFrame.S_2 = pd.to_datetime(dataFrame.S_2)\n",
    "\n",
    "    \n",
    "    dataFrame = dataFrame.fillna(-127)\n",
    "    print('shape of data:', dataFrame.shape)\n",
    "\n",
    "    return dataFrame\n",
    "\n",
    "\n",
    "print('Reading train data...')\n",
    "TRAIN_PATH = 'train.parquet'\n",
    "train = read_parquet(path=TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ea0fccf",
   "metadata": {
    "id": "8ea0fccf",
    "outputId": "634a8b52-bf94-426b-fba3-ac5f275eedcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after engineering (458913, 918)\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    :param df: pandas dataframe of train dataset\n",
    "    :return: feature engineered data\n",
    "    \n",
    "    \"\"\"\n",
    "    all_col_of_df = [c for c in list(df.columns) if c not in ['customer_ID', 'S_2']]\n",
    "    cat_features = [\"B_30\", \"B_38\", \"D_114\", \"D_116\", \"D_117\", \"D_120\", \"D_126\", \"D_63\", \"D_64\", \"D_66\", \"D_68\"]\n",
    "    num_features = [col for col in all_col_of_df if col not in cat_features]\n",
    "\n",
    "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "\n",
    "    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "\n",
    "    df = pd.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print('shape after engineering', df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_engineering(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f863c901",
   "metadata": {
    "id": "f863c901",
    "outputId": "49a57066-8a40-4f6e-86b7-aafe7d64412f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 918 features!\n"
     ]
    }
   ],
   "source": [
    "# ADD TARGETS\n",
    "output_var = pd.read_csv('C:/Users/shant/Downloads/train_labels.csv')\n",
    "output_var['customer_ID'] = output_var['customer_ID'].str[-16:].apply(int, base=16).astype('int64')\n",
    "output_var = output_var.set_index('customer_ID')\n",
    "train = train.merge(output_var, left_index=True, right_index=True, how='left')\n",
    "train.target = train.target.astype('int8')\n",
    "del output_var\n",
    "\n",
    "\n",
    "train = train.sort_index().reset_index()\n",
    "\n",
    "# FEATURES\n",
    "FEATURES = train.columns[1:-1]\n",
    "print(f'There are {len(FEATURES)} features!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58cdd978",
   "metadata": {
    "id": "58cdd978",
    "outputId": "f187d89f-8670-4940-f87f-d199944e64e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['P_2_mean', 'P_2_std', 'P_2_min', 'P_2_max', 'P_2_last', 'D_39_mean',\n",
       "       'D_39_std', 'D_39_min', 'D_39_max', 'D_39_last',\n",
       "       ...\n",
       "       'D_63_nunique', 'D_64_count', 'D_64_last', 'D_64_nunique', 'D_66_count',\n",
       "       'D_66_last', 'D_66_nunique', 'D_68_count', 'D_68_last', 'D_68_nunique'],\n",
       "      dtype='object', length=918)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ae8fd26",
   "metadata": {
    "id": "5ae8fd26",
    "outputId": "cf5662b5-d6f3-4695-cdea-a1c35b7d498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['P_2_std', 'D_39_std', 'B_1_std', 'B_2_std', 'R_1_std', 'S_3_std',\n",
       "       'D_41_std', 'B_3_std', 'D_42_std', 'D_43_std',\n",
       "       ...\n",
       "       'D_136_std', 'D_137_std', 'D_138_std', 'D_139_std', 'D_140_std',\n",
       "       'D_141_std', 'D_142_std', 'D_143_std', 'D_144_std', 'D_145_std'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()[train.isnull().sum() != 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec124c6",
   "metadata": {
    "id": "dec124c6",
    "outputId": "e7f80a13-8ede-4446-db15-d00f344fc0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records removed:  5120\n",
      "% of customers removed from data:  1.1156798783211632\n"
     ]
    }
   ],
   "source": [
    "shape_before_remove = train.shape[0]\n",
    "train = train.dropna()\n",
    "print('Number of records removed: ',abs(shape_before_remove - train.shape[0]))\n",
    "print('% of customers removed from data: ', abs(shape_before_remove - train.shape[0]) * 100 /shape_before_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f710104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(453793, 918)\n",
      "(453793,)\n"
     ]
    }
   ],
   "source": [
    "X = train.drop(labels=['customer_ID','target'], axis = 1)\n",
    "y = train.loc[:,'target']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856474a",
   "metadata": {},
   "source": [
    "### Random Forest model on Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246a1da",
   "metadata": {},
   "source": [
    "The Random Forests model was analyzed with several runs for the following set of parameters with different number of trees i.e., starting from 100 to 500 trees with an increment of 100 trees each time to determine the optimal number of trees.  \n",
    "\n",
    "Criterion =  ‘gini’: Gini index for calculating information gain.  \n",
    "\n",
    "max_features : ‘sqrt’: Square root of the total number of features in individual run. \n",
    "\n",
    "Bootstrap = True:  Samples are drawn with replacement \n",
    "\n",
    "random_state = 1: Controls randomness of the sample\n",
    "\n",
    "It was observed that changing the number of trees did not affect the test performance significantly. Hence, the number of trees set to 100 being computationally inexpensive and for algorithm to generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e55b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e67d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  8.5min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    4.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100,\n",
    "                           criterion='gini',\n",
    "                           random_state=1,\n",
    "                           max_features='sqrt',\n",
    "                           bootstrap=True,\n",
    "                           n_jobs=2, verbose=True)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18b7c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93    100948\n",
      "           1       0.80      0.79      0.80     35190\n",
      "\n",
      "    accuracy                           0.90    136138\n",
      "   macro avg       0.86      0.86      0.86    136138\n",
      "weighted avg       0.89      0.90      0.90    136138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1acd6da",
   "metadata": {},
   "source": [
    "Evaluating the results of trained Random Forest model for performance metrics show 93% recall for class 0 and 79% for class 1, with an accuracy of 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189b284",
   "metadata": {},
   "source": [
    "### Attempt for Grid Search for Optimal Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ffdc4d",
   "metadata": {},
   "source": [
    "To improve the performance furthermore, we aim to obtain optimal parameters thereby performing Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2f1f5",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators' : [10, 20, 40, 60, 80],\n",
    "             'criterion' : ['gini'],\n",
    "             'max_depth': [5, 7, 10, 15, 20, 50],\n",
    "              'max_features' : ['sqrt'],\n",
    "              'bootstrap' : [True]\n",
    "              }\n",
    "rf_grid = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rf_grid, param_grid, n_jobs=5, cv=5, verbose=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "grid_search.best_estimator_\n",
    "\n",
    "y_pred1 = grid_search.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred1))\n",
    "print(\"F1-score:\",metrics.f1_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b5058",
   "metadata": {},
   "source": [
    "It kept processing for more that 24hours without any results and hence conclused to interrupt the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45f008",
   "metadata": {},
   "source": [
    "### Random Forest model with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc69fb2",
   "metadata": {},
   "source": [
    "The dataset includes imbalanced classes, to overcome this bias, we need a balanced distribution of classes. Since, performing SMOTE (Synthetic Minority Oversampling Technique) on whole datase creates overfitting, thus only applied to training set to gain operational performace and test set provides an estimate on the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2c6f54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed: 13.3min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    4.8s finished\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "clf_sm=RandomForestClassifier(n_estimators=100,\n",
    "                              criterion='gini',\n",
    "                              random_state=1,\n",
    "                              max_features='sqrt',\n",
    "                              bootstrap=True,\n",
    "                              n_jobs=2, verbose=True)\n",
    "clf_sm.fit(X_train_oversampled,y_train_oversampled)\n",
    "\n",
    "y_pred_sm=clf_sm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70fd1e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92    100948\n",
      "           1       0.76      0.85      0.80     35190\n",
      "\n",
      "    accuracy                           0.89    136138\n",
      "   macro avg       0.85      0.88      0.86    136138\n",
      "weighted avg       0.90      0.89      0.89    136138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b4db4",
   "metadata": {},
   "source": [
    "Model trained over SMOTE dataset clearly show improved recall for 85% for class 1, however a reduced 90% for class 0 and 89% accuracy on test dataset. However, no considerable change in f1-score in comparison to the results obtained for the earlier model. Nevertheless, an overall improved accuracy in predicting True Positives and True Negatives was achieved. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
